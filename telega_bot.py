# telega_asr_tts.py
import os
import json
import wave
import shutil
import subprocess
import tempfile
from pathlib import Path
import traceback

import telebot
import numpy as np
import soundfile as sf
from vosk import Model as VoskModel, KaldiRecognizer
import whisper as openai_whisper

# Optional libs (import failures are allowed ‚Äî we'll try available TTS backends)
try:
    import torch
except Exception:
    torch = None

try:
    from gtts import gTTS
except Exception:
    gTTS = None

try:
    from huggingface_hub import login as hf_login
    from transformers import pipeline as hf_pipeline
except Exception:
    hf_pipeline = None
    hf_login = None

# ---------------- CONFIG ----------------
BOT_TOKEN = "8594216688:AAGQ-ZCOgJI-0Dk4cKKwjFbkJPsYyHE4C_8"
VOSK_MODEL_PATH = r"C:\Users\User\Downloads\vosk-model-kz-0.42\vosk-model-kz-0.42"
HF_TOKEN = os.environ.get("HF_TOKEN", "")

TMP_DIR = Path(tempfile.gettempdir()) / "tg_asr_tts_bot"
TMP_DIR.mkdir(parents=True, exist_ok=True)

# ---------------- INIT ----------------
bot = telebot.TeleBot(BOT_TOKEN)

if not os.path.exists(VOSK_MODEL_PATH):
    raise FileNotFoundError(f"Vosk –º–æ–¥–µ–ª—å—ñ —Ç–∞–±—ã–ª–º–∞–¥—ã: {VOSK_MODEL_PATH}")

print("üì¶ Vosk –º–æ–¥–µ–ª—ñ–Ω –∂“Ø–∫—Ç–µ—É...")
vosk_model = VoskModel(VOSK_MODEL_PATH)
print("‚úÖ Vosk –¥–∞–π—ã–Ω")

print("üì¶ Whisper –º–æ–¥–µ–ª—ñ–Ω –∂“Ø–∫—Ç–µ—É (GPU “Ø—à—ñ–Ω device='cuda'):")
device = "cuda"
try:
    whisper_model = openai_whisper.load_model("large-v3", device=device)
    print("‚úÖ Whisper –¥–∞–π—ã–Ω (GPU)")
except Exception as e:
    print("‚ö†Ô∏è Whisper GPU —ñ—Å–∫–µ “õ–æ—Å—ã–ª–º–∞–¥—ã, CPU —Ä–µ–∂–∏–º—ñ–Ω–µ –∞—É—ã—Å–∞–º—ã–∑:", e)
    whisper_model = openai_whisper.load_model("large-v3", device="cpu")
    print("‚úÖ Whisper –¥–∞–π—ã–Ω (CPU)")

# ---------------- TTS INIT ----------------
silero_tts = None
if torch is not None:
    try:
        silero_tts = torch.hub.load('snakers4/silero-models', 'silero_tts', language='multi', speaker='bayan')
        print("‚úÖ Silero TTS –¥–∞–π—ã–Ω (multi/speaker=bayan)")
    except Exception as e:
        print("‚Ñπ Silero TTS –∂“Ø–∫—Ç–µ–ª–º–µ–¥—ñ:", e)
        silero_tts = None

hf_tts = None
if HF_TOKEN and hf_pipeline is not None:
    try:
        if hf_login:
            try:
                hf_login(HF_TOKEN)
            except Exception:
                pass
        HF_MODEL_ID = "facebook/mms-tts-kaz"
        hf_tts = hf_pipeline("text-to-speech", model=HF_MODEL_ID, token=HF_TOKEN)
        print("‚úÖ Hugging Face TTS pipeline –¥–∞–π—ã–Ω:", HF_MODEL_ID)
    except Exception as e:
        print("‚Ñπ HF TTS pipeline “õ–æ–ª–¥–∞–Ω—ã–ª–º–∞–¥—ã:", e)
        hf_tts = None

# ---------------- HELPERS ----------------
def run_ffmpeg_convert(in_path: str, out_path: str, sr: int = 16000):
    subprocess.run(
        ["ffmpeg", "-y", "-i", in_path, "-ar", str(sr), "-ac", "1", out_path],
        stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL
    )

def transcribe_vosk(wav_path: str) -> str:
    with wave.open(wav_path, "rb") as wf:
        rec = KaldiRecognizer(vosk_model, wf.getframerate())
        rec.SetWords(False)
        text = ""
        while True:
            data = wf.readframes(4000)
            if len(data) == 0:
                break
            if rec.AcceptWaveform(data):
                res = json.loads(rec.Result())
                text += (res.get("text", "") + " ")
        final = json.loads(rec.FinalResult())
        text += final.get("text", "")
    return text.strip()

def transcribe_whisper(wav_path: str) -> str:
    result = whisper_model.transcribe(wav_path, language="kk")
    if isinstance(result, dict):
        return result.get("text", "").strip()
    return str(result).strip()

def save_float_audio_as_pcm16(wav_path: str, float_array: np.ndarray, sr: int):
    if float_array.dtype not in (np.float32, np.float64):
        float_array = float_array.astype(np.float32)
    maxv = np.max(np.abs(float_array)) if float_array.size > 0 else 1.0
    if maxv == 0:
        maxv = 1.0
    int16 = np.int16(float_array / maxv * 32767)
    sf.write(wav_path, int16, sr, subtype="PCM_16")

def tts_silero(text: str, out_wav: str) -> bool:
    if silero_tts is None:
        return False
    try:
        if hasattr(silero_tts, "save_wav"):
            silero_tts.save_wav(text=text, speaker='bayan', sample_rate=48000, audio_path=out_wav)
            return True
        else:
            audio = silero_tts.apply_tts(text=text, speaker='bayan')
            if hasattr(audio, "cpu"):
                audio = audio.cpu().numpy()
            save_float_audio_as_pcm16(out_wav, np.asarray(audio), 48000)
            return True
    except Exception as e:
        print("Silero TTS error:", e)
        return False

def tts_hf_pipeline(text: str, out_wav: str) -> bool:
    if hf_tts is None:
        return False
    try:
        res = hf_tts(text)
        if isinstance(res, dict) and "audio" in res:
            save_float_audio_as_pcm16(out_wav, np.asarray(res["audio"]), res.get("sampling_rate", 48000))
            return True
        return False
    except Exception as e:
        print("HF TTS error:", e)
        return False

def tts_gtts(text: str, out_wav: str) -> bool:
    if gTTS is None:
        return False
    try:
        tmp_mp3 = out_wav + ".mp3"
        try:
            gTTS(text=text, lang="kk").save(tmp_mp3)
        except Exception:
            gTTS(text=text, lang="ru").save(tmp_mp3)
        subprocess.run([
            "ffmpeg", "-y", "-i", tmp_mp3,
            "-acodec", "pcm_s16le", "-ar", "48000", "-ac", "1", out_wav
        ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
        os.remove(tmp_mp3)
        return os.path.exists(out_wav)
    except Exception as e:
        print("gTTS error:", e)
        return False

def make_tts_any(text: str, out_wav: str) -> bool:
    if tts_silero(text, out_wav):
        return True
    if tts_hf_pipeline(text, out_wav):
        return True
    if tts_gtts(text, out_wav):
        return True
    return False

# ---------------- BOT HANDLERS ----------------
@bot.message_handler(commands=["start", "help"])
def send_welcome(message):
    bot.reply_to(message, "–°”ô–ª–µ–º! –ê—É–¥–∏–æ –∂—ñ–±–µ—Ä ‚Äî –º–µ–Ω –æ–Ω—ã –º”ô—Ç—ñ–Ω–≥–µ –∞–π–Ω–∞–ª–¥—ã—Ä—ã–ø, “õ–∞–π—Ç–∞ “õ–∞–∑–∞“õ—à–∞ —Å”©–π–ª–µ–π–º—ñ–Ω (–±—ñ—Ä–Ω–µ—à–µ TTS –±–∞—Ä).")

@bot.message_handler(content_types=['voice', 'audio'])
def handle_voice(message):
    username = message.from_user.username or message.from_user.first_name or "–ë–µ–π—Ç–∞–Ω—ã—Å"
    user_id = message.from_user.id
    print(f"\nüîµ {username} (id={user_id}) –∂–∞“£–∞ –∞—É–¥–∏–æ –∂—ñ–±–µ—Ä–¥—ñ.")

    tmp_base = TMP_DIR / f"{message.message_id}"
    tmp_base.mkdir(parents=True, exist_ok=True)
    ogg_path = str(tmp_base / "voice.ogg")
    wav_path = str(tmp_base / "voice_16k.wav")
    reply_wav = str(tmp_base / "reply_48k.wav")

    try:
        file_id = message.voice.file_id if hasattr(message, "voice") else message.audio.file_id
        file_info = bot.get_file(file_id)
        data = bot.download_file(file_info.file_path)
        with open(ogg_path, "wb") as f:
            f.write(data)

        run_ffmpeg_convert(ogg_path, wav_path, sr=16000)

        vosk_text = transcribe_vosk(wav_path)
        try:
            whisper_text = transcribe_whisper(wav_path)
        except Exception:
            whisper_text = ""

        chosen = whisper_text.strip() if (whisper_text and len(whisper_text) > len(vosk_text)) else vosk_text.strip()
        if not chosen:
            chosen = "–°”©–π–ª–µ—É —Ç–∞–±—ã–ª–º–∞–¥—ã."

        print(f"üó£ –¢–∞–Ω—ã–ª“ì–∞–Ω –º”ô—Ç—ñ–Ω (Vosk): {vosk_text}")
        print(f"ü§ñ –¢–∞–Ω—ã–ª“ì–∞–Ω –º”ô—Ç—ñ–Ω (Whisper): {whisper_text}")
        print(f"‚úÖ –¢–∞“£–¥–∞–ª“ì–∞–Ω –Ω”ô—Ç–∏–∂–µ: {chosen}")

        reply_text = (
            f"üéô Vosk –Ω”ô—Ç–∏–∂–µ—Å—ñ:\n{vosk_text}\n\n"
            f"üß† Whisper –Ω”ô—Ç–∏–∂–µ—Å—ñ:\n{whisper_text}\n\n"
            f"‚úÖ –°–æ“£“ì—ã –Ω”ô—Ç–∏–∂–µ:\n{chosen}"
        )
        bot.reply_to(message, reply_text)

        ok = make_tts_any(chosen, reply_wav)
        if ok:
            with open(reply_wav, "rb") as af:
                bot.send_voice(message.chat.id, af, reply_to_message_id=message.message_id)
                print(f"üì§ {username} –ø–∞–π–¥–∞–ª–∞–Ω—É—à—ã—Å—ã–Ω–∞ –∂–∞—É–∞–ø –∂—ñ–±–µ—Ä—ñ–ª–¥—ñ.\n")
        else:
            bot.reply_to(message, "‚ö†Ô∏è TTS –∂–∞—Å–∞—É –º“Ø–º–∫—ñ–Ω –±–æ–ª–º–∞–¥—ã.")

    except Exception as e:
        tb = traceback.format_exc()
        print("Handle voice exception:", e, tb)
        bot.reply_to(message, f"‚ö†Ô∏è “ö–∞—Ç–µ: {e}")
    finally:
        shutil.rmtree(tmp_base, ignore_errors=True)

# ---------------- RUN ----------------
if __name__ == "__main__":
    print("ü§ñ –ë–æ—Ç —ñ—Å–∫–µ “õ–æ—Å—ã–ª–¥—ã.")
    bot.infinity_polling()
